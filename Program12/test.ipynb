{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import names\n",
    "from nltk.classify import DecisionTreeClassifier\n",
    "from nltk import classify\n",
    "from nltk import FreqDist\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['female.txt', 'male.txt']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abagael',\n",
       " 'Abagail',\n",
       " 'Abbe',\n",
       " 'Abbey',\n",
       " 'Abbi',\n",
       " 'Abbie',\n",
       " 'Abby',\n",
       " 'Abigael',\n",
       " 'Abigail',\n",
       " 'Abigale']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.words(fileids='female.txt')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(words):\n",
    "    return dict(FreqDist(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "documents = [(list(names.words(fileid)), fileid.split('.')[0]) for fileid in names.fileids()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = int(len(documents) * 0.8)\n",
    "train_set, test_set = documents[:split_ratio], documents[split_ratio:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training_features \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategory\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategory\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\n\u001b[1;32m      2\u001b[0m \u001b[43mtrain_set\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      3\u001b[0m testing_features \u001b[38;5;241m=\u001b[39m [(extract_features(words), category) \u001b[38;5;28;01mfor\u001b[39;00m (words, category) \u001b[38;5;129;01min\u001b[39;00m\n\u001b[1;32m      4\u001b[0m test_set]\n",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training_features \u001b[38;5;241m=\u001b[39m [(\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m, category) \u001b[38;5;28;01mfor\u001b[39;00m (words, category) \u001b[38;5;129;01min\u001b[39;00m\n\u001b[1;32m      2\u001b[0m train_set]\n\u001b[1;32m      3\u001b[0m testing_features \u001b[38;5;241m=\u001b[39m [(extract_features(words), category) \u001b[38;5;28;01mfor\u001b[39;00m (words, category) \u001b[38;5;129;01min\u001b[39;00m\n\u001b[1;32m      4\u001b[0m test_set]\n",
      "Cell \u001b[0;32mIn[37], line 2\u001b[0m, in \u001b[0;36mextract_features\u001b[0;34m(words)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_features\u001b[39m(words):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(ConditionalFreqDist(\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgender\u001b[49m\u001b[43m,\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgender\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwords\u001b[49m\u001b[43m]\u001b[49m))\n",
      "Cell \u001b[0;32mIn[37], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_features\u001b[39m(words):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(ConditionalFreqDist([(gender,name) \u001b[38;5;28;01mfor\u001b[39;00m (name,gender) \u001b[38;5;129;01min\u001b[39;00m words]))\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "training_features = [(extract_features(words), category) for (words, category) in\n",
    "train_set]\n",
    "testing_features = [(extract_features(words), category) for (words, category) in\n",
    "test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier.train(training_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = classify.accuracy(classifier, testing_features)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sentences = ['Abagael',\n",
    " 'Abagail',\n",
    " 'Abbe',\n",
    " 'Abbey',\n",
    " 'Abbi',\n",
    " 'Abbie',\n",
    " 'Abby',\n",
    " 'Abigael',\n",
    " 'Abigail',\n",
    " 'Abigale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted category for 'Abagael': male\n",
      "Predicted category for 'Abagail': male\n",
      "Predicted category for 'Abbe': male\n",
      "Predicted category for 'Abbey': male\n",
      "Predicted category for 'Abbi': male\n",
      "Predicted category for 'Abbie': male\n",
      "Predicted category for 'Abby': male\n",
      "Predicted category for 'Abigael': male\n",
      "Predicted category for 'Abigail': male\n",
      "Predicted category for 'Abigale': male\n"
     ]
    }
   ],
   "source": [
    "for sentence in new_sentences:\n",
    "    words = word_tokenize(sentence)\n",
    "    features = extract_features(words)\n",
    "    category = classifier.classify(features)\n",
    "    print(f\"Predicted category for '{sentence}': {category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
